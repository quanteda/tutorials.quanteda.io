---
title: Target-word collocations
weight: 40
draft: false
---

```{r message=FALSE}
require(quanteda)
```

This corpus contains 6,000 Guardian news articles from 2012 to 2016.

```{r eval=FALSE}
corp_news <- download('data_corpus_guardian')
```

```{r include=FALSE}
# This code is only for website generation
corp_news <- readRDS("../data/data_corpus_guardian.rds")
```

```{r}
ndoc(corp_news)
range(corp_news$date)

toks_news <- tokens(corp_news, remove_punct = TRUE)
```

### Keywords for Brexit

We can also find words associated with target words using the `window` argument of `tokens_select()`. 

```{r}
toks_brexit <- tokens_keep(toks_news, pattern = 'brexit', window = 10) # equivalent to tokens_select(selection = 'keep')
toks_nobrexit <- tokens_remove(toks_news, pattern = 'brexit', window = 10) # equivalent to tokens_select(selection = 'remove')
print(toks_brexit[['text173244']])

dfmat_brexit <- dfm(toks_brexit)
dfmat_nobrexit <- dfm(toks_nobrexit)

tstat_key_brexit <- textstat_keyness(rbind(dfmat_brexit, dfmat_nobrexit), seq_len(ndoc(dfmat_brexit)))
tstat_key_brexit_subset <- tstat_key_brexit[tstat_key_brexit$n_target > 10, ]
head(tstat_key_brexit_subset, 50)
```

### Keywords for Trump

Targeted frequency analysis might look complex, but can be done in five lines.

```{r}
trump <- c('donald trump', 'trump')
dfmat_trump <- tokens_keep(toks_news, pattern = phrase(trump), window = 10) %>% 
    dfm()

dfmat_no_trump <- tokens_remove(toks_news, pattern = phrase(trump), window = 10) %>%
    dfm()
tstat_key_trump <- textstat_keyness(rbind(dfmat_trump, dfmat_no_trump), seq_len(ndoc(dfmat_trump)))

tstat_key_trump_subset <- tstat_key_trump[tstat_key_trump$n_target > 10, ]
head(tstat_key_trump_subset, 50)
```
